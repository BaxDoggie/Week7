“Slow data are gathered painstakingly over time, entailing effort in collection, storage, and processing, and in the process retaining their context, comprehensibility, and organization. This accords with the typical image of the craft of archaeological recording, which even with increasing digitalization remains a relatively slow process for the most part, at least for now.” (Huggett, 2022, pp. 102) 

This quote resonated with me because it reflects the tension I experienced while working with neural network-based tools. AI promises rapid outputs, but meaningful results still depend on careful human effort in data collection, preparation, and interpretation.  


I started the work this week with the image classifier. I ran through the premade classifier for pottery and found it quite interesting to see it work and to trick it with lower quality images of things it was trained on. Using the example as a template, I then made my own classifier for Roman coins. I grabbed photos of the fronts and backs of Roman coins and trained my classifier. For this section of the week, I wouldn't say I had any real losses, I had to make some adjustments to get things working properly, but it went smoothly so I would classify this whole section as a win. As for how I feel about this section, I found it quite fun and interesting. I see how tools like these could certainly be useful and save a lot of time, especially if you had a large database to classify. I also saw how tools like this can cause issues; they are never perfectly accurate, especially if the images you are classifying have different angles, quality, and wear on the item. I also see how your training data needs to be large and very though out otherwise its size cold spiral out of control 


The Practical Necromancy notebook, which trained GPT-2 on Petrie’s writings, further emphasized the limits of generative AI. My generated text captured some stylistic elements but became repetitive and nonsensical, demonstrating that fluency does not equal comprehension. It also raised ethical and epistemic questions; AI can imitate historical voices, potentially producing plausible but misleading outputs. Both experiments revealed friction not in coding alone but in the human effort needed to maintain meaningful context and quality. They demonstrated the impressive capabilities of AI, while reminding me that speed and volume cannot replace careful, slow work. 

These experiences reinforced the importance of reflection, context, and labour in digital archaeology. Neural networks are powerful tools, but their outputs are meaningful only when connected to thoughtful human interpretation, careful curation, and attention to the slow, painstaking work that underpins reliable archaeological knowledge. Building the coin classifier after the pottery example made me particularly aware of how much effort is hidden behind seemingly effortless results, and how crucial it is to retain context and comprehensibility, just as Huggett emphasizes in his discussion of slow data. 